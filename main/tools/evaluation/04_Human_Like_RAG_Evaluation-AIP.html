<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Notebook 4: RAG Human-Like Evaluation - LLM-as-a-Judge &mdash; NVIDIA Generative AI Examples 24.6.0 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/omni-style.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
    <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script src="../../_static/version.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="search" title="Search" href="../../search.html" />
 


</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >


<a href="../../index.html">
  <img src="../../_static/nvidia-logo-white.png" class="logo" alt="Logo"/>
</a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">RAG Pipelines for Developers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../index.html">About the RAG Pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../support-matrix.html">Support Matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api-catalog.html">API Catalog Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../query-decomposition.html">Query Decomposition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../structured-data.html">Structured Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../multimodal-data.html">Multimodal Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../multi-turn.html">Multi-turn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../using-sample-web-application.html">Sample Chat Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../vector-database.html">Alternative Vector Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nim-llms.html">NIM for LLMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../simple-examples.html">Developing Simple Examples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tools</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../observability.html">Observability</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Jupyter Notebooks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/01_dataloader.html">Press Release Chat Bot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/02_Option%281%29_NVIDIA_AI_endpoint_simple.html">NVIDIA API Catalog with LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/02_Option%282%29_minimalistic_RAG_with_langchain_local_HF_LLM.html">LangChain with Local Llama 2 Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/03_Option%281%29_llama_index_with_NVIDIA_AI_endpoint.html">NVIDIA API Catalog, LlamaIndex, and LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/03_Option%282%29_llama_index_with_HF_local_LLM.html">HF Checkpoints with LlamaIndex and LangChain</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/04_Agent_use_tools_leveraging_NVIDIA_AI_endpoints.html">Multimodal Models from NVIDIA AI Catelog and AI Catalog with LangChain Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/05_RAG_for_HTML_docs_with_Langchain_NVIDIA_AI_Endpoints.html">Build a RAG chain by generating embeddings for NVIDIA Triton documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/06_LangGraph_HandlingAgent_IntermediateSteps.html">LangGraph Handling LangChain Agent Intermediate_Steps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/07_Chat_with_nvidia_financial_reports.html">Notebook: Chatting with NVIDIA Financial Reports</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/08_RAG_Langchain_with_Local_NIM.html">Build a RAG using a locally hosted NIM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/agentic_rag_with_nemo_retriever_nims.html">Agentic RAG pipeline with Nemo Retriever and LLM NIMs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Software Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../architecture.html">Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../frontend.html">RAG Playground Web Application</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../jupyter-server.html">Jupyter Notebook Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../chain-server.html">Chain Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../configuration.html">Software Component Configuration</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">NVIDIA Generative AI Examples</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Notebook 4: RAG Human-Like Evaluation - LLM-as-a-Judge</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="notebook-4-rag-human-like-evaluation-llm-as-a-judge">
<h1>Notebook 4: RAG Human-Like Evaluation - LLM-as-a-Judge<a class="headerlink" href="#notebook-4-rag-human-like-evaluation-llm-as-a-judge" title="Permalink to this headline"></a></h1>
<p>In this notebook, we are going to use a high quality LLM to generate evaluation scores (human-like) for RAG system final outputs.</p>
<p>We will use Llama3 70B model to evaluate the example RAG pipeline.
The score granulaity is from 1 to 5 where:</p>
<ul class="simple">
<li><p><strong>Score 1</strong>: Answer irrelevant or invalid, does not follow the context of the question or is irrelevant</p></li>
<li><p><strong>Score 2</strong>: Answer barely useable, missing significant accurate information</p></li>
<li><p><strong>Score 3</strong>: Answer mostly helpful, missing some information or added erroneous information</p></li>
<li><p><strong>Score 4</strong>: Answer helpful, room for some improvement, could be more concise</p></li>
<li><p><strong>Score 5</strong>: Answer helpful, accurate, relevant and concise</p></li>
</ul>
<section id="step-1-load-the-data">
<h2>Step 1: Load the Data<a class="headerlink" href="#step-1-load-the-data" title="Permalink to this headline"></a></h2>
<p>Let’s first load the JSON dataset. The structure should be:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">{</span>
<span class="go">&#39;gt_context&#39;: chunk,</span>
<span class="go">&#39;document&#39;: filename,</span>
<span class="go">&#39;question&#39;: &quot;xxxxx&quot;,</span>
<span class="go">&#39;gt_answer&#39;: &quot;xxx xxx xxxx&quot;,</span>
<span class="go">&#39;contexts&#39;: &quot;xxx xxx xxxx&quot;,</span>
<span class="go">&#39;answer&#39;:&quot;xxx xxx xxxx&quot;,</span>
<span class="go">}</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>

<span class="c1"># The path to your JSON file</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="s1">&#39;eval.json&#39;</span>

<span class="c1"># Read the JSON file</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Check some of the loaded data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of entries&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Get your <a class="reference external" href="https://build.nvidia.com/explore/discover#llama3-70b">API key for Nvidia API Catalog for the meta/llama3-70b-instruct model</a> and populate it in the below cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>

<span class="n">invoke_url</span> <span class="o">=</span> <span class="s2">&quot;https://integrate.api.nvidia.com/v1/chat/completions&quot;</span> <span class="c1">#Llama 3 70B Instruct</span>
<span class="c1"># do not remove Bearer from Authorization, replace &lt;REPLACE_THIS_WITH_API_KEY&gt; with api key</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Authorization&quot;</span><span class="p">:</span> <span class="s2">&quot;Bearer &lt;REPLACE_THIS_WITH_API_KEY&gt;&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Accept&quot;</span><span class="p">:</span> <span class="s2">&quot;application/json&quot;</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="step-2-design-the-llm-as-a-judge-prompt">
<h2>Step 2: Design the LLM-as-a-Judge Prompt<a class="headerlink" href="#step-2-design-the-llm-as-a-judge-prompt" title="Permalink to this headline"></a></h2>
<p>The evaluation axes are the helpfulness, relevance, accuracy, and level of detail. Prompting the high quality LLM to generate human-like evaluation requires a careful prompt engineering with an explicit instructions</p>
<p>We must provide the evaluation criteria and the methodology in the same fashion as if we were giving human instructions on how to evaluate.
We also ask the LLM to consider both the reference answer and context (ground truth) when evaluating the response provided by the RAG pipeline.
Finally, we ask the LLM to provide a score on a scale of 1-5 (likert scale) and ask it to provide an explanation.</p>
<p>Here is an example of judge_template that we will use with Llama3 70B. Notice the evaluation examples provided in the prompt. This will help guide the LLM.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">LLAMA_PROMPT_TEMPLATE</span> <span class="o">=</span> <span class="p">(</span>
 <span class="s2">&quot;&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;&quot;</span>
 <span class="s2">&quot;</span><span class="si">{system_prompt}</span><span class="s2">&quot;</span>
 <span class="s2">&quot;&lt;&lt;/SYS&gt;&gt;&quot;</span>
 <span class="s2">&quot;&quot;</span>
 <span class="s2">&quot;Example 1:&quot;</span>
 <span class="s2">&quot;[Question]&quot;</span>
 <span class="s2">&quot;When did Queen Elizabeth II die?&quot;</span>
 <span class="s2">&quot;[The Start of the Reference Context]&quot;</span>
<span class="w"> </span><span class="sd">&quot;&quot;&quot;On 8 September 2022, Buckingham Palace released a statement which read: &quot;Following further evaluation this morning, the Queen&#39;s doctors are concerned for Her Majesty&#39;s health and have recommended she remain under medical supervision. The Queen remains comfortable and at Balmoral.&quot;[257][258] Her immediate family rushed to Balmoral to be by her side.[259][260] She died peacefully at 15:10 BST at the age of 96, with two of her children, Charles and Anne, by her side;[261][262] Charles immediately succeeded as monarch. Her death was announced to the public at 18:30,[263][264] setting in motion Operation London Bridge and, because she died in Scotland, Operation Unicorn.[265][266] Elizabeth was the first monarch to die in Scotland since James V in 1542.[267] Her death certificate recorded her cause of death as old age&quot;&quot;&quot;</span>
 <span class="s2">&quot;[The End of Reference Context]&quot;</span>
 <span class="s2">&quot;[The Start of the Reference Answer]&quot;</span>
 <span class="s2">&quot;Queen Elizabeth II died on September 8, 2022.&quot;</span>
 <span class="s2">&quot;[The End of Reference Answer]&quot;</span>
 <span class="s2">&quot;[The Start of the Assistant&#39;s Answer]&quot;</span>
 <span class="s2">&quot;She died on September 8, 2022&quot;</span>
 <span class="s2">&quot;[The End of Assistant&#39;s Answer]&quot;</span>
 <span class="s1">&#39;&quot;Rating&quot;: 5, &quot;Explanation&quot;: &quot;The answer is helpful, relevant, accurate, and concise. It matches the information provided in the reference context and answer.&quot;&#39;</span>
 <span class="s2">&quot;&quot;</span>
 <span class="s2">&quot;Example 2:&quot;</span>
 <span class="s2">&quot;[Question]&quot;</span>
 <span class="s2">&quot;When did Queen Elizabeth II die?&quot;</span>
 <span class="s2">&quot;[The Start of the Reference Context]&quot;</span>
<span class="w"> </span><span class="sd">&quot;&quot;&quot;On 8 September 2022, Buckingham Palace released a statement which read: &quot;Following further evaluation this morning, the Queen&#39;s doctors are concerned for Her Majesty&#39;s health and have recommended she remain under medical supervision. The Queen remains comfortable and at Balmoral.&quot;[257][258] Her immediate family rushed to Balmoral to be by her side.[259][260] She died peacefully at 15:10 BST at the age of 96, with two of her children, Charles and Anne, by her side;[261][262] Charles immediately succeeded as monarch. Her death was announced to the public at 18:30,[263][264] setting in motion Operation London Bridge and, because she died in Scotland, Operation Unicorn.[265][266] Elizabeth was the first monarch to die in Scotland since James V in 1542.[267] Her death certificate recorded her cause of death as old age&quot;&quot;&quot;</span>
 <span class="s2">&quot;[The End of Reference Context]&quot;</span>
 <span class="s2">&quot;[The Start of the Reference Answer]&quot;</span>
 <span class="s2">&quot;Queen Elizabeth II died on September 8, 2022.&quot;</span>
 <span class="s2">&quot;[The End of Reference Answer]&quot;</span>
 <span class="s2">&quot;[The Start of the Assistant&#39;s Answer]&quot;</span>
 <span class="s2">&quot;Queen Elizabeth II was the longest reigning monarch of the United Kingdom and the Commonwealth.&quot;</span>
 <span class="s2">&quot;[The End of Assistant&#39;s Answer]&quot;</span>
 <span class="s1">&#39;&quot;Rating&quot;: 1, &quot;Explanation&quot;: &quot;The answer is not helpful or relevant. It does not answer the question and instead goes off topic.&quot;&#39;</span>
  <span class="s2">&quot;&quot;</span>
 <span class="s2">&quot;Follow the exact same format as above. Put Rating first and Explanation second. Rating must be between 1 and 5. What is the rating and explanation for the following assistant&#39;s answer&quot;</span>
 <span class="s2">&quot;[Question]&quot;</span>
 <span class="s2">&quot;</span><span class="si">{question}</span><span class="s2">&quot;</span>
 <span class="s2">&quot;[The Start of the Reference Context]&quot;</span>
 <span class="s2">&quot;</span><span class="si">{ctx_ref}</span><span class="s2">&quot;</span>
 <span class="s2">&quot;[The End of Reference Context]&quot;</span>
 <span class="s2">&quot;[The Start of the Reference Answer]&quot;</span>
 <span class="s2">&quot;</span><span class="si">{answer_ref}</span><span class="s2">&quot;</span>
 <span class="s2">&quot;[The End of Reference Answer]&quot;</span>
 <span class="s2">&quot;[The Start of the Assistant&#39;s Answer]&quot;</span>
 <span class="s2">&quot;</span><span class="si">{answer}</span><span class="s2">&quot;</span>
 <span class="s2">&quot;[The End of Assistant&#39;s Answer][/INST]&quot;</span>
<span class="p">)</span>

<span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">You are an impartial judge that evaluates the quality of an assistant&#39;s answer to the question provided.</span>
<span class="s2">You evaluation takes into account helpfullness, relevancy, accuracy, and level of detail of the answer.</span>
<span class="s2">You must use both the reference context and reference answer to guide your evaluation.</span>
<span class="s2">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>Now call the Judge LLM on the RAG results</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># re-use connections</span>
<span class="n">session</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>

<span class="n">llama_judge_responses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="n">LLAMA_PROMPT_TEMPLATE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">system_prompt</span><span class="o">=</span><span class="n">system_prompt</span><span class="p">,</span> <span class="n">question</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">],</span> <span class="n">ctx_ref</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;gt_context&quot;</span><span class="p">],</span> <span class="n">answer_ref</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;gt_answer&quot;</span><span class="p">],</span> <span class="n">answer</span><span class="o">=</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
        <span class="n">payload</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;messages&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="p">{</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt</span><span class="p">,</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span>
                <span class="p">}</span>
            <span class="p">],</span>
            <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="s2">&quot;meta/llama3-70b-instruct&quot;</span><span class="p">,</span>
            <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="s2">&quot;top_p&quot;</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">,</span>
            <span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
            <span class="s2">&quot;stream&quot;</span><span class="p">:</span> <span class="kc">False</span>
            <span class="p">}</span>

        <span class="n">response</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">invoke_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">payload</span><span class="p">)</span>

        <span class="k">while</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">202</span><span class="p">:</span>
            <span class="n">request_id</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">headers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;NVCF-REQID&quot;</span><span class="p">)</span>
            <span class="n">fetch_url</span> <span class="o">=</span> <span class="n">fetch_url_format</span> <span class="o">+</span> <span class="n">request_id</span>
            <span class="n">response</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">fetch_url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">)</span>

        <span class="n">response_body</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>
        <span class="n">llama_judge_responses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">response_body</span><span class="p">[</span><span class="s1">&#39;choices&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;progress: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">llama_judge_responses</span><span class="p">)</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exception:&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
        <span class="n">llama_judge_responses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Parse the rating and evaluations out of the Judge responses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">statistics</span>

<span class="c1"># Regular expression pattern to extract rating and explanation</span>
<span class="n">rating_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;Rating:\s*(\d+)&#39;</span>
<span class="n">explanation_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;Explanation:\s*(.+)&#39;</span>

<span class="n">llama_ratings</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">llama_explanations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">llama_judge_responses</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
                <span class="c1"># Search for the patterns</span>
                <span class="n">rating_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">rating_pattern</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>
                <span class="n">explanation_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">explanation_pattern</span><span class="p">,</span> <span class="n">response</span><span class="p">)</span>

                <span class="c1"># Extract and print the rating and explanation</span>
                <span class="n">llama_ratings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">rating_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span> <span class="k">if</span> <span class="n">rating_match</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
                <span class="n">llama_explanations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">explanation_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">explanation_match</span> <span class="k">else</span> <span class="n">response</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Exception&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
                <span class="n">llama_ratings</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="n">llama_explanations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s take a peek at the results!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of judgements:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">llama_ratings</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">llama_ratings</span><span class="p">)]):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Question:&quot;</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Reference Answer:&quot;</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;gt_answer&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Answer:&quot;</span><span class="p">,</span> <span class="n">d</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Rating:&quot;</span><span class="p">,</span> <span class="n">llama_ratings</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Explanation:&quot;</span><span class="p">,</span> <span class="n">llama_explanations</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;*************************************&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s calculate the mean Likert score and then display a historgram of all the ratings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate mean</span>
<span class="n">llama_ratings</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">r</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">llama_ratings</span><span class="p">]</span> <span class="c1"># Change 0 ratings to 1</span>
<span class="n">llama_ratings_filtered</span> <span class="o">=</span> <span class="p">[</span><span class="n">r</span> <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="n">llama_ratings</span> <span class="k">if</span> <span class="n">r</span> <span class="p">]</span> <span class="c1"># Remove empty ratings</span>
<span class="n">mean</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">statistics</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">llama_ratings_filtered</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of ratings:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">llama_ratings_filtered</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean rating: </span><span class="si">{</span><span class="n">mean</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.ticker</span> <span class="kn">import</span> <span class="n">MaxNLocator</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="c1"># Set the style of the visualization</span>
<span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

<span class="c1"># Create a histogram</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">llama_ratings_filtered</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">],</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mf">.5</span><span class="p">,</span> <span class="mf">5.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_major_locator</span><span class="p">(</span><span class="n">MaxNLocator</span><span class="p">(</span><span class="n">integer</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="c1"># Add titles and labels</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Ratings&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Rating&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>

<span class="c1"># Show the plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Lastly, let’s write your evaluation results to a csv file so you can examine them in more detail later.</p>
<p>Note: A few LLM Judge evaluation responses may be malformed and therefore unparseable. In these cases the rating and explanation fields will be empty.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">csv</span>

<span class="n">results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">llama_ratings</span><span class="p">,</span>
                   <span class="n">llama_explanations</span><span class="p">,</span>
                   <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;question&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],</span>
                   <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;answer&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],</span>
                   <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;gt_answer&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">],</span>
                   <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;gt_context&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]))</span>

<span class="n">output_file</span> <span class="o">=</span> <span class="s1">&#39;judgements.csv&#39;</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_file</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>

    <span class="c1"># headers</span>
    <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">([</span><span class="s1">&#39;Rating&#39;</span><span class="p">,</span> <span class="s1">&#39;Explanation&#39;</span><span class="p">,</span> <span class="s1">&#39;Question&#39;</span><span class="p">,</span> <span class="s1">&#39;Answer&#39;</span><span class="p">,</span> <span class="s1">&#39;Groundtruth Answer&#39;</span><span class="p">,</span> <span class="s1">&#39;Groundtruth Context&#39;</span><span class="p">])</span>

    <span class="c1"># Write the data</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
        <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Data written to </span><span class="si">{</span><span class="n">output_file</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Bonus! A good practice for improving a RAG pipeline is to look at the responses that were rated poorly and then determine actions to improve.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">bad_result</span> <span class="k">for</span> <span class="n">bad_result</span> <span class="ow">in</span> <span class="n">results</span> <span class="k">if</span> <span class="n">bad_result</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023-2024, NVIDIA Corporation.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 



</body>
</html>